{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"axis3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMfO8N9wKTQ/6TyR+BqVkl0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Translation done in Translation.ipynb"],"metadata":{"id":"VhvM6bILOlcq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZYDzvIAyOfHl"},"outputs":[],"source":["# predict data Path :\n","# data_path = '/export/home/cse200093/brat_data/Expe_TRANSL/expe_translation_Gold_after_conversion_train_test/test_eng_opus-FT_txt'\n","data_path = '/export/home/cse200093/brat_data/QUAERO_FrenchMed/corpus/test/EMEA_en_opus-FT_txt'\n","# data_path = '/export/home/cse200093/brat_data/n2c2_2019/test_restrict_proc_chem_devi_diso'\n","# data_path = '/export/home/cse200093/brat_data/n2c2_2019/train_restrict_proc_chem_devi_diso'\n","# Mantra/English\n","# data_path = '/export/home/cse200093/brat_data/Mantra_English'\n","\n","\n","# vocab path and cdb path\n","DATA_DIR = \"/export/home/cse200093/MedCAT\"\n","vocab_path = DATA_DIR + \"/vocab.dat\"\n","cdb_path = DATA_DIR + \"/cdb-umls-v1.dat\"\n","\n","# res_path = \"/export/home/cse200093/Expe_Translation/results/MedCAT_Gold_test_en_opus-FT\"\n","res_path = '/export/home/cse200093/Expe_Translation/results/MedCAT_EMEA_test_en_opus-FT'\n","# res_path = '/export/home/cse200093/Expe_Translation/results/MedCAT_n2c2_2019_test'\n","# res_path = '/export/home/cse200093/Expe_Translation/results/MedCAT_n2c2_2019_train'\n","# res_path = '/export/home/cse200093/Expe_Translation/results/MedCAT_Mantra_English'"]},{"cell_type":"code","source":["# gold standard path\n","# stand_path = '/export/home/cse200093/brat_data/Expe_TRANSL/expe_translation_Gold_after_conversion_train_test/test/'\n","stand_path = '/export/home/cse200093/brat_data/QUAERO_FrenchMed/corpus/test/EMEA/'\n","# stand_path = '/export/home/cse200093/brat_data/n2c2_2019/test_restrict_proc_chem_devi_diso/'\n","# stand_path = '/export/home/cse200093/brat_data/n2c2_2019/train_restrict_proc_chem_devi_diso/'\n","# stand_path = '/export/home/cse200093/brat_data/Mantra_English/'"],"metadata":{"id":"7QOuumHROpu7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","import os\n","from tqdm import tqdm\n","import shutil\n","from spacy import displacy\n","import gensim\n","from tokenizers import ByteLevelBPETokenizer\n","from gensim.models import Word2Vec\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import json \n","from matplotlib import pyplot as plt\n","\n","from medcat.cat import CAT\n","from medcat.cdb import CDB\n","from medcat.config import Config\n","from medcat.vocab import Vocab\n","from medcat.meta_cat import MetaCAT\n","from medcat.config_meta_cat import ConfigMetaCAT\n","from medcat.preprocessing.tokenizers import TokenizerWrapperBPE, TokenizerWrapperBERT\n","from tokenizers import ByteLevelBPETokenizer"],"metadata":{"id":"gLvlMa63Otm6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# map a type code in umls to a semantic type\n","dic_typecode2type = {}\n","f = open('/export/home/cse200093/Expe_Translation/Axes_script/umls_group_info.txt', 'r')\n","for line in tqdm(f):\n","    line = line.rstrip('\\n')\n","    ents = line.split('|')\n","    type_name = ents[0]\n","    type_name_spe = ents[-1]\n","    type_code = ents[2]\n","    dic_typecode2type[type_code] = type_name\n","f.close()\n","\n","len(dic_typecode2type)"],"metadata":{"id":"cCISFucaOxor"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build model with cdb and vocab\n","\n","# Create and load the CDB (Concept Database)\n","cdb = CDB.load(cdb_path)\n","# Create and load the Vocabulary\n","vocab = Vocab.load(vocab_path)\n","# Setup config\n","config = Config()\n","config.general['spacy_model'] = 'en_core_web_md'\n","# Get the required tokenizer (note that we have already downloaded the required models)\n","mc = MetaCAT.load('/export/home/cse200093/Expe_Translation/Status')\n","# To add the meta-annotation model to the medcat pipeline\n","cat = CAT(cdb=cdb, config=config, vocab=vocab, meta_cats=[mc])"],"metadata":{"id":"50AWwNk9O4DC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# read predict data\n","os.chdir(data_path)\n","my_files = glob.glob('*.txt')\n","len(my_files)"],"metadata":{"id":"4JxUda97PBMT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# read all txt files and put them in a dataframe\n","df_text = pd.DataFrame(columns=['file_name','text_english'])\n","\n","for file_name in tqdm(my_files):\n","    f = open(data_path+\"/\"+file_name, \"r\")\n","    text = f.read()\n","    f.close()\n","    #print(text)\n","    df_text = df_text.append({'file_name':file_name, 'text_english':text}, ignore_index=True)\n","    \n","df_text"],"metadata":{"id":"3X7H9e7XPEhS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Anotate documents\n","# format the df_text to match: required input data for multiprocessing = [(doc_id, doc_text), (doc_id, doc_text), ...]\n","def data_iterator(data):\n","    for id, row in data[['text_english']].iterrows():\n","        yield (id, str(row['text_english']))"],"metadata":{"id":"7Oc5R2qDPF48"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set a batch size to control for the variablity between document sizes\n","batch_size_chars = 500000 # Batch size (BS) in number of characters\n","\n","# Run model\n","results = cat.multiprocessing(data_iterator(df_text),  # Formatted data\n","                              batch_size_chars = batch_size_chars,\n","                              nproc=8) # Number of processors"],"metadata":{"id":"gSfnpT3dPKM6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save results\n","f = open(res_path, 'w')\n","\n","for key in results:\n","    filename = my_files[key]\n","    f.write(filename+'\\n')\n","    entities = results[key]['entities']\n","    for ent in entities:\n","        if len(entities[ent]['type_ids']) != 0:\n","            line = entities[ent]['pretty_name']+'\\t'+entities[ent]['cui']+'\\t'+entities[ent]['type_ids'][0]+'\\t'+entities[ent]['types'][0]\n","        else:\n","            line = entities[ent]['pretty_name']+'\\t'+entities[ent]['cui']+'\\t'+'unknown_typeId'+'\\t'+'unknown_type'\n","\n","        f.write(line+'\\n')\n","    f.write('\\n')\n","\n","f.close()"],"metadata":{"id":"TXb9UAVOPLv7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["keep_types = ['CHEM','DEVI','DISO','PROC']"],"metadata":{"id":"o-wO3bubPO4K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function to read precedently saved results of MedCAT\n","def read_results_cui(path):\n","    # dictionary containing file name as keys and a list of cuis as values\n","    dic_file_ent = {}\n","\n","    # read result files to fill dic\n","    f = open(path, 'r')\n","    #lines = [line.rstrip('\\n') for line in f]\n","    key = None\n","    for line in tqdm(f):\n","        line = line.rstrip('\\n')\n","        if line.endswith('.txt'):\n","            dic_file_ent[line[:-4]] = []\n","            key = line[:-4]\n","        elif line == '':\n","            continue\n","        else:\n","            ent = line.split('\\t')\n","            cui = ent[1]\n","            type_code = ent[2]\n","#             dic_file_ent[key].append(cui)\n","            # filter 4 types\n","            if type_code != 'unknown_typeId' and type_code != 'unk' and dic_typecode2type[type_code] in keep_types:\n","                type_name = dic_typecode2type[type_code]\n","                dic_file_ent[key].append(cui)\n","            else:\n","                continue\n","    f.close()\n","    \n","    return dic_file_ent"],"metadata":{"id":"1v7wtCj1PQZz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dic_file_ent_built = read_results_cui(res_path)\n","len(dic_file_ent_built)"],"metadata":{"id":"3ecLkY3EPWR7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# read gold standard\n","os.chdir(stand_path)\n","my_files = glob.glob('*.ann')\n","len(my_files)"],"metadata":{"id":"UHxOnDG-PX3L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dictionary containing correct results\n","dic_file_ent_standard = {}\n","\n","for file in tqdm(my_files):\n","    dic_file_ent_standard[file[:-4]] = []\n","    f = open(stand_path+file, 'r')\n","    for line in f:\n","        line = line.rstrip('\\n')\n","        if line.startswith('T'):\n","            type_name = line.split('\\t')[1].split(' ')[0]\n","        if line.startswith('#'):\n","            eles = line.split('\\t')\n","            #print(eles)\n","            cui = eles[-1]\n","            # filter 4 types\n","            if type_name in keep_types:\n","                dic_file_ent_standard[file[:-4]].append(cui)\n","        else:\n","            continue"],"metadata":{"id":"X1nsIKFzPa7T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_list_to_dic(dic):\n","    for file_name in tqdm(dic):\n","        key_list = list(set(dic[file_name]))\n","        value_list = [dic[file_name].count(x) for x in key_list]\n","        res = dict(zip(key_list, value_list))\n","        dic[file_name] = res"],"metadata":{"id":"E0j8u6A2Pb4J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["convert_list_to_dic(dic_file_ent_built)\n","convert_list_to_dic(dic_file_ent_standard)"],"metadata":{"id":"hFzGYwi7Pdjk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_compare = pd.DataFrame(columns = ['file_name','correct_ents','built_model_ents'])\n","\n","for file in tqdm(dic_file_ent_standard):\n","    df_compare = df_compare.append({'file_name':file, 'correct_ents':dic_file_ent_standard[file], \n","                       'built_model_ents':dic_file_ent_built[file]},\n","                     ignore_index=True)\n","    \n","df_compare"],"metadata":{"id":"KOU7fl2GPe0i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_compare['built_TP'] = 0\n","df_compare['built_FP'] = 0\n","df_compare['built_FN'] = 0\n","\n","df_compare['built_precision'] = 0\n","df_compare['built_recall'] = 0\n","df_compare['built_f1-score'] = 0\n","\n","# calculate TP,FP,FN for each model\n","for index, row in tqdm(df_compare.iterrows()):\n","    for cui in row['built_model_ents']:\n","        if cui in row['correct_ents']:\n","            df_compare.loc[index,'built_TP'] += min(row['correct_ents'][cui], row['built_model_ents'][cui])\n","        else:\n","            df_compare.loc[index,'built_FP'] += row['built_model_ents'][cui]\n","    for cui in row['correct_ents']:\n","        if cui not in row['built_model_ents']:\n","            df_compare.loc[index,'built_FN'] += row['correct_ents'][cui]\n","            \n","            \n","# calculate precision and recall for each model\n","for index, row in tqdm(df_compare.iterrows()):\n","    if row['built_TP'] != 0:\n","        df_compare.loc[index,'built_precision'] = row['built_TP']/(row['built_TP']+row['built_FP'])\n","\n","    if row['built_TP'] != 0:\n","        df_compare.loc[index,'built_recall'] = row['built_TP']/(row['built_TP']+row['built_FN'])\n","\n","# calculate f1-score for each model\n","for index, row in tqdm(df_compare.iterrows()):\n","    if row['built_TP'] != 0:\n","        df_compare.loc[index,'built_f1-score'] = (2*row['built_precision']*row['built_recall'])/(row['built_precision']+row['built_recall'])\n","            \n","\n","df_compare"],"metadata":{"id":"fugJQvtqPf7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate mean precision, mean recall, mean f1-score\n","\n","built_avg_precision = np.mean(df_compare['built_precision'])\n","built_avg_recall = np.mean(df_compare['built_recall'])\n","built_avg_f1_score = np.mean(df_compare['built_f1-score'])\n","\n","print(f'Average precision of the built model: {built_avg_precision}')\n","print(f'Average recall of the built model: {built_avg_recall}')\n","print(f'Average f1-score of the built model: {built_avg_f1_score}')"],"metadata":{"id":"hqRNDBHtPhBV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save df_compare for boostrap.ipynb\n","df_compare.to_pickle('/export/home/cse200093/Expe_Translation/Axes_script/EMEA_res_axis3.pkl')"],"metadata":{"id":"PG1lA7aLPiYL"},"execution_count":null,"outputs":[]}]}
