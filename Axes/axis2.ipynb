{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"axis2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMYBZEAmr7Wh+pYVIRB/LGj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XlTxg5FQMULo"},"outputs":[],"source":["import glob\n","import os\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import torch\n","import pickle\n","\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","\n","batch_size = 128\n","device = \"cuda:6\""]},{"cell_type":"markdown","source":["Translation done in translation.ipynb\n","\n","English NER done in nlstruct_predict.ipynb\n","\n","Normalization done in deep_mlg_inference_script.ipynb\n","\n","results saved in a pkl file"],"metadata":{"id":"I7spfZUENpS7"}},{"cell_type":"code","source":["# read results\n","gold_file_transl = '/export/home/cse200093/deep_mlg_normalization/df_mentions_EMEA_test_en_4_types.pkl'\n","open_file = open(gold_file_transl, \"rb\")\n","df_res = pickle.load(open_file)\n","open_file.close()\n","\n","df_res.rename(columns={'cui_res':'cuis'},inplace=True)\n","#df_res = df_res[(df_res['label']=='PROC')|(df_res['label']=='DEVI')|(df_res['label']=='DISO')|(df_res['label']=='CHEM')]\n","df_res"],"metadata":{"id":"vAhML5GWMYEC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# gold standard path\n","# stand_path = '/export/home/cse200093/brat_data/Expe_TRANSL/expe_translation_Gold_after_conversion_train_test/test/'\n","stand_path = '/export/home/cse200093/brat_data/QUAERO_FrenchMed/corpus/test/EMEA'"],"metadata":{"id":"YngOsq6bOAcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# select all ann files\n","os.chdir(stand_path)\n","my_files = glob.glob('*.ann')\n","len(my_files)"],"metadata":{"id":"RCZVcn9eOG77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["phrases = []\n","cuis = []\n","types = []\n","dic = {} # necessary when len(phrases) != len(cuis)\n","for file in tqdm(my_files):\n","    phrase = None\n","    code = None\n","    type_name = None\n","    f = open(stand_path+'/'+file, \"r\")\n","    for line in f:\n","        line = line.rstrip('\\n')\n","        if line.startswith('T'):\n","            type_name = line.split('\\t')[1].split(' ')[0]\n","            phrase = line.split('\\t')[2]\n","            code = line.split('\\t')[0] # necessary when len(phrases) != len(cuis)\n","            dic[file+'.'+phrase+'.'+code] = 'no cui' # necessary when len(phrases) != len(cuis)\n","            #phrases.append(phrase)\n","            #types.append(type_name)\n","        elif line.startswith('#'):\n","            cui = line.split('\\t')[-1]\n","            dic[file+'.'+phrase+'.'+code] = (cui,type_name) # necessary when len(phrases) != len(cuis)\n","            #cui = cui.split(',')[0][1:].rstrip('\\\"') # necessary for Mantra\n","            #cuis.append(cui)"],"metadata":{"id":"pqnCMAY_OJU7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# necessary when len(phrases) != len(cuis)\n","print(len(dic))\n","no_cuis = []\n","files = []\n","# phrases_eng = []\n","dic_file_ent = {}\n","for key in tqdm(dic):\n","    if dic[key] != 'no cui':\n","        phrases.append(key.split('.')[2])\n","        # necessary with translation\n","        # phrases_eng.append(translator.translate(key.split('.')[2]).text)\n","        cuis.append(dic[key][0])\n","        types.append(dic[key][1])\n","        file = key.split('.')[0]\n","        files.append(file)\n","        if file in dic_file_ent.keys():\n","            dic_file_ent[file].append(key.split('.')[2])\n","        else:\n","            dic_file_ent[file] = [key.split('.')[2]]\n","    else:\n","        #print(key)\n","        no_cuis.append(key)\n","        \n","print(len(cuis),len(phrases),len(types),len(files),len(dic_file_ent))"],"metadata":{"id":"cnQB8tQ3OKry"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_stand = pd.DataFrame({'doc_id':files, 'phrases':phrases, 'cuis':cuis, 'types':types})\n","df_stand = df_stand[(df_stand['types']=='PROC')|(df_stand['types']=='DEVI')|(df_stand['types']=='DISO')|(df_stand['types']=='CHEM')]\n","df_stand"],"metadata":{"id":"tLo1a5hUOMFd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_dic(df):\n","    dic = {}\n","    docs = list(df['doc_id'])\n","    for doc in docs:\n","        cuis = list(df[df['doc_id']==doc]['cuis'])\n","        dic[doc] = cuis\n","    return dic"],"metadata":{"id":"hToJrbL2ONMR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_list_to_dic(dic):\n","    for file_name in tqdm(dic):\n","        key_list = list(set(dic[file_name]))\n","        value_list = [dic[file_name].count(x) for x in key_list]\n","        res = dict(zip(key_list, value_list))\n","        dic[file_name] = res"],"metadata":{"id":"p0bHjHVfOOnV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dic_stand = get_dic(df_stand)\n","dic_res = get_dic(df_res)\n","\n","convert_list_to_dic(dic_stand)\n","convert_list_to_dic(dic_res)"],"metadata":{"id":"8WEX_oBFOP0J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_compare = pd.DataFrame(columns = ['file_name','correct_ents','pred_ents','text'])\n","\n","for file in tqdm(dic_stand):\n","    df_compare = df_compare.append({'file_name':file, 'correct_ents':dic_stand[file], \n","                       'pred_ents':dic_res[file], 'text':dic_file_ent[file]},\n","                     ignore_index=True)\n","    \n","df_compare"],"metadata":{"id":"ibp-n_h8OSub"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_compare['built_TP'] = 0\n","df_compare['built_FP'] = 0\n","df_compare['built_FN'] = 0\n","\n","df_compare['built_precision'] = 0\n","df_compare['built_recall'] = 0\n","df_compare['built_f1-score'] = 0\n","\n","# calculate TP,FP,FN for each model\n","for index, row in tqdm(df_compare.iterrows()):\n","    for cui in row['pred_ents']:\n","        if cui in row['correct_ents']:\n","            df_compare.loc[index,'built_TP'] += min(row['correct_ents'][cui], row['pred_ents'][cui])\n","        else:\n","            df_compare.loc[index,'built_FP'] += row['pred_ents'][cui]\n","    for cui in row['correct_ents']:\n","        if cui not in row['pred_ents']:\n","            df_compare.loc[index,'built_FN'] += row['correct_ents'][cui]\n","            \n","            \n","# calculate precision and recall for each model\n","for index, row in tqdm(df_compare.iterrows()):\n","    if row['built_TP'] != 0:\n","        df_compare.loc[index,'built_precision'] = row['built_TP']/(row['built_TP']+row['built_FP'])\n","\n","    if row['built_TP'] != 0:\n","        df_compare.loc[index,'built_recall'] = row['built_TP']/(row['built_TP']+row['built_FN'])\n","\n","# calculate f1-score for each model\n","for index, row in tqdm(df_compare.iterrows()):\n","    if row['built_TP'] != 0:\n","        df_compare.loc[index,'built_f1-score'] = (2*row['built_precision']*row['built_recall'])/(row['built_precision']+row['built_recall'])\n","            \n","\n","df_compare"],"metadata":{"id":"ygRtlFTKOT-6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate mean precision, mean recall, mean f1-score\n","\n","built_avg_precision = np.mean(df_compare['built_precision'])\n","built_avg_recall = np.mean(df_compare['built_recall'])\n","built_avg_f1_score = np.mean(df_compare['built_f1-score'])\n","\n","print(f'Average precision of the built model: {built_avg_precision}')\n","print(f'Average recall of the built model: {built_avg_recall}')\n","print(f'Average f1-score of the built model: {built_avg_f1_score}')"],"metadata":{"id":"EAM2phszOVKq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save df_compare for boostrap.ipynb\n","df_compare.to_pickle('/export/home/cse200093/Expe_Translation/Axes_script/EMEA_res_axis2.pkl')"],"metadata":{"id":"WAZAig9TOWo6"},"execution_count":null,"outputs":[]}]}