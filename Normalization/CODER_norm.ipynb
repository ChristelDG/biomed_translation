{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CODER_norm.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyODhC6WBLrlUjBp0ls9K32m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Use CODER to normalize concepts"],"metadata":{"id":"DYPuXJo0Dlx8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"37Oo4LZIDjkJ"},"outputs":[],"source":["from gensim import models\n","import os\n","import sys\n","import glob\n","# path tp load_umls\n","sys.path.append(\"../../\")\n","from load_umls import UMLS\n","\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","import tqdm\n","import pickle\n","\n","batch_size = 128\n","device = \"cuda:6\""]},{"cell_type":"code","source":["def get_bert_embed(phrase_list, m, tok, normalize=True, summary_method=\"CLS\", tqdm_bar=False):\n","    input_ids = []\n","    for phrase in phrase_list:\n","        input_ids.append(tok.encode_plus(\n","            phrase, max_length=32, add_special_tokens=True,\n","            truncation=True, pad_to_max_length=True)['input_ids'])\n","    m.eval()\n","\n","    count = len(input_ids)\n","    now_count = 0\n","    with torch.no_grad():\n","        if tqdm_bar:\n","            pbar = tqdm.tqdm(total=count)\n","        while now_count < count:\n","            input_gpu_0 = torch.LongTensor(input_ids[now_count:min(\n","                now_count + batch_size, count)]).to(device)\n","            if summary_method == \"CLS\":\n","                embed = m(input_gpu_0)[1]\n","            if summary_method == \"MEAN\":\n","                embed = torch.mean(m(input_gpu_0)[0], dim=1)\n","            if normalize:\n","                embed_norm = torch.norm(\n","                    embed, p=2, dim=1, keepdim=True).clamp(min=1e-12)\n","                embed = embed / embed_norm\n","            if now_count == 0:\n","                output = embed\n","            else:\n","                output = torch.cat((output, embed), dim=0)\n","            if tqdm_bar:\n","                pbar.update(min(now_count + batch_size, count) - now_count)\n","            now_count = min(now_count + batch_size, count)\n","        if tqdm_bar:\n","            pbar.close()\n","    return output"],"metadata":{"id":"Tql_I5GdDt6y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load umls_embedding\n","umls_embedding = torch.load('umls_embedding_en_fr_coder_eng.pt', map_location=device) # CODER_en & en_fr UMLS"],"metadata":{"id":"IFfzdfpiD5JC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load terms, cuis and semantic groups\n","open_file = open('umls_label_en_fr_coder_eng.pkl', \"rb\")\n","umls_label = pickle.load(open_file)\n","open_file.close()\n","\n","open_file = open('umls_des_en_fr_coder_eng.pkl', \"rb\")\n","umls_des = pickle.load(open_file)\n","open_file.close()\n","\n","open_file = open('umls_en_fr_cui2sty_coder_eng.pkl', \"rb\")\n","umls_cui2sty = pickle.load(open_file)\n","open_file.close()"],"metadata":{"id":"EsStVi3FD8gp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load CODER model\n","model_checkpoint = '/export/home/cse200093/coder_eng'\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","model = AutoModel.from_pretrained(model_checkpoint).to(device)"],"metadata":{"id":"E-1ButXIEH1y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# predict data path\n","data_path = '/export/home/cse200093/brat_data/n2c2_2019/test_restrict_proc_chem_devi_diso/'"],"metadata":{"id":"QGxAquU-EUVS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# select all ann files\n","os.chdir(data_path)\n","my_files = glob.glob('*.ann')\n","len(my_files)"],"metadata":{"id":"OdsCB6F0EarI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["phrases = []\n","cuis = []\n","types = []\n","dic = {} # necessary when len(phrases) != len(cuis)\n","for file in tqdm.tqdm(my_files):\n","    phrase = None\n","    code = None\n","    type_name = None\n","    f = open(data_path+file, \"r\")\n","    for line in f:\n","        line = line.rstrip('\\n')\n","        if line.startswith('T'):\n","            type_name = line.split('\\t')[1].split(' ')[0]\n","            phrase = line.split('\\t')[2]\n","            code = line.split('\\t')[0] # necessary when len(phrases) != len(cuis)\n","            dic[file+'.'+phrase+'.'+code] = 'no cui' # necessary when len(phrases) != len(cuis)\n","            #phrases.append(phrase)\n","            #types.append(type_name)\n","        elif line.startswith('#'):\n","            cui = line.split('\\t')[2]\n","            dic[file+'.'+phrase+'.'+code] = (cui,type_name) # necessary when len(phrases) != len(cuis)\n","            #cui = cui.split(',')[0][1:].rstrip('\\\"') # necessary for Mantra\n","            #cuis.append(cui)"],"metadata":{"id":"hJOQJrd8EfqC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# necessary when len(phrases) != len(cuis)\n","print(len(dic))\n","no_cuis = []\n","# phrases_eng = []\n","for key in tqdm.tqdm(dic):\n","    if dic[key] != 'no cui':\n","        phrases.append(key.split('.')[2])\n","        # necessary with translation\n","        # phrases_eng.append(translator.translate(key.split('.')[2]).text)\n","        cuis.append(dic[key][0])\n","        types.append(dic[key][1])\n","    else:\n","        #print(key)\n","        no_cuis.append(key)\n","        \n","print(len(cuis),len(phrases),len(types))"],"metadata":{"id":"kPmVvXcVEi-K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame({'phrases':phrases, 'cuis':cuis, 'types':types})\n","df"],"metadata":{"id":"_RDAZGBzEkli"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# filter 4 types\n","df = df[(df['types']=='PROC')|(df['types']=='DEVI')|(df['types']=='DISO')|(df['types']=='CHEM')]\n","phrases = list(df['phrases'])\n","cuis = list(df['cuis'])\n","types = list(df['types'])\n","\n","len(phrases)"],"metadata":{"id":"C3kIzhhLEoTy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get embedding for predict data\n","text_embedding = get_bert_embed(phrases, model, tokenizer)"],"metadata":{"id":"zGWk6odQEukp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prediction considering type information\n","def predict(umls_label, text_embedding, umls_embedding, cui2sty, start, end, gold_type):\n","    x_size = text_embedding.size(0)\n","    sim = torch.matmul(text_embedding[start:end], umls_embedding.t())\n","    most_similar = torch.max(sim, dim=1)[1]\n","    most_similar_cui = [umls_label[idx] for idx in most_similar]\n","    candidates = torch.topk(sim, k=nb, dim=1, sorted=True).indices\n","    #candidates = [check(candidate.tolist(), sim[0]) for candidate in candidates]\n","    candidate_cuis = [[umls_label[idx] for idx in candidate] for candidate in candidates]\n","    #print(candidate_cuis)\n","    candidate_stys = [[cui2sty[cui] for cui in cuis] for cuis in candidate_cuis]\n","    candidate_types = [[sty2type[sty] for sty in stys] for stys in candidate_stys]\n","    pred = [candidate_cuis[i][choose(candidate_types[i],gold_type[start:end][i])] for i in range(len(candidates))]\n","    ks = [choose(candidate_types[i],gold_type[start:end][i]) for i in range(len(candidates))]\n","    #[umls_label[idx] for idx in most_similar]\n","#     for i in range(len(most_similar_cui)):\n","#         if sty2type[cui2sty[most_similar_cui[i]]] == gold_type[i]:\n","#             pred[i] = most_similar_cui[i]\n","    return (pred,ks)"],"metadata":{"id":"EU29l9FvE0KW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(pred, stand, types, phrases, ks=None):\n","    hit = 0\n","    if ks is not None:\n","        df_err = pd.DataFrame(columns=['cui_res','cui_stand','type','text','k'])\n","    else:\n","        df_err = pd.DataFrame(columns=['cui_res','cui_stand','type','text'])\n","    cui_res_l = []\n","    cui_stand_l = []\n","    type_l = []\n","    text_l = []\n","    ks_l = []\n","    for i in range(len(pred)):\n","        if pred[i] == stand[i]:\n","            hit+=1\n","            #print(pred[i],stand[i],types[i],phrases[i])\n","        else:\n","            cui_res_l.append(pred[i])\n","            cui_stand_l.append(stand[i])\n","            type_l.append(types[i])\n","            text_l.append(phrases[i])\n","            if ks is not None:\n","                ks_l.append(ks[i])\n","\n","    acc = hit/len(pred)\n","    df_err['cui_res'] = cui_res_l\n","    df_err['cui_stand'] = cui_stand_l\n","    df_err['type'] = type_l\n","    df_err['text'] = text_l\n","    if ks is not None:\n","        df_err['k'] = ks_l\n","    print(acc, hit)\n","    return (df_err,acc)"],"metadata":{"id":"JMZgnqAWE7ZJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# when too many terms to predict, choose start and end to normalize only part of them\n","start = 0\n","end = 500\n","\n","pred1,ks = predict(umls_label, text_embedding, umls_embedding, umls_cui2sty, start, end, types)"],"metadata":{"id":"HWWy_NdjE-KS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate overall accuracy and give errors\n","df_err,acc = accuracy(pred1,cuis[begin:end],types[begin:end],phrases[begin:endp],ks)"],"metadata":{"id":"MvNmWVUYFRJC"},"execution_count":null,"outputs":[]}]}